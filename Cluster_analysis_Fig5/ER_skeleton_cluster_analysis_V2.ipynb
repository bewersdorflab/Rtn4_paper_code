{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b7519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PYME.LMVis import VisGUI\n",
    "\n",
    "%gui wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabdd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pymevis = VisGUI.ipython_pymevisualize()\n",
    "pipeline = pymevis.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6702e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PYME.IO import tabular\n",
    "\n",
    "# PARAMETERS to Change\n",
    "min_dist = 10       #minimum distance between skeleton vertices in determining the vector that points from each vertex\n",
    "                    #to the closest vertex that's at least this distance away (helps make nice backbone vectors)\n",
    "max_dist = 50       #maximum distance between skeleton vertices. This helps speed up the KDTree query\n",
    "max_nn = 200        #maximum # of nearest neighbors before collapsing them into one point\n",
    "ball_r = 50         #radius used for query_ball_points\n",
    "#asprat_thresh = 1.5 # the minimum asprect ratio that cluster sigma0/sigma1 must have (std dev of major and intermediate axes)\n",
    "#en = 1              #experiment number (1-3) or 0 for figure 5 tubule data\n",
    "clust_min = 3                                           # Clusters with less than this # of points will be excluded\n",
    "Rtn4_chan = 'chan1'    # channel name for Rtn4 data\n",
    "rtn_save = 'rtn4_screenshot'\n",
    "\n",
    "high_filt=100          # Threshold for max distance a Rtn4 point can be from mesh and still be included in analysis\n",
    "low_filt=-100          # Threshold for min distance a Rtn4 point can be from mesh and still be included in analysis\n",
    "\n",
    "savedir = 'K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_analysis_V2\\\\Real_data_analysis'\n",
    "ver = 'V2'\n",
    "\n",
    "datadir = [\"K:\\\\4Pi_data\\Oligomer_analysis\\\\Oligomer_data\\\\20210907_data\\\\Cell02_DBSCAN-2_ROI_all-clumped_DBSCAN-clusters_measureClusters3D.csv\",\n",
    "           \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20220930_data\\\\Cell04_ROI1_all-clumped_MeasureCluster3D_DBSCAN.csv\",\n",
    "           \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20221004_data\\\\Cell05_ROI4_all-clumped_measureClusters3D.csv\"]\n",
    "c_points = [\"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20210907_data\\\\Cell02_DBSCAN-2_ROI_all-clumped_DBSCAN-clusters.hdf\",\n",
    "            \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20220930_data\\\\Cell04_ROI1_all-clumped_DBSCAN_Clusters.hdf\",\n",
    "            \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20221004_data\\\\Cell05_ROI4_all-clumped_DBSCAN_Clusters.hdf\"]\n",
    "mesh_fn = [\"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20210907_data\\\\Cell02_DBSCAN-2_ROI_shrinkwrap.stl\",\n",
    "               \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20220930_data\\\\Cell04_ROI1_shrinkwrap_1.stl\",\n",
    "               \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20221004_data\\\\Cell05_ROI4_shrinkwrap.stl\"]\n",
    "skelly = [\"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20210907_data\\\\Cell02_DBSCAN-2_ROI_skeleton.stl\",\n",
    "          \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20220930_data\\\\Cell04_ROI1_skeleton.stl\",\n",
    "          \"K:\\\\4Pi_data\\\\Oligomer_analysis\\\\Oligomer_data\\\\20221004_data\\\\Cell05_ROI4_skeleton.stl\"]\n",
    "d_name = ['20210907_Cell02','20220930_Cell04','20221004_Cell05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69499c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PYME.IO import tabular\n",
    "\n",
    "# generate 3D Gaussian\n",
    "# points = np.random.randn(100,3)*100\n",
    "\n",
    "#######################################################################################################################\n",
    "# Define needed functions\n",
    "#######################################################################################################################\n",
    "\n",
    "def add_ds_from_Nx3(points, pipeline, pymevis, ds_name='points', color=None, normals=None):\n",
    "    \"\"\"\n",
    "    Quickly add points/normals to the pipeline and pymevis display.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = {'x': points[:,0], 'y': points[:,1], 'z': points[:,2]}\n",
    "    \n",
    "    if color is not None:\n",
    "        d['c'] = color\n",
    "        \n",
    "    if normals is not None:\n",
    "        d['xn'] = normals[:,0]\n",
    "        d['yn'] = normals[:,1]\n",
    "        d['zn'] = normals[:,2]\n",
    "\n",
    "    # create tabular mappingFilter data source and add it to pymevis\n",
    "    pipeline.addDataSource(ds_name, tabular.mappingFilter(d))\n",
    "\n",
    "    # select this data source (optional, but helps support \"default behavior\")\n",
    "    pipeline.selectDataSource(ds_name)\n",
    "\n",
    "    # Add a pointcloud layer that displays data source named 'points' (the one we just added)\n",
    "    pymevis.add_pointcloud_layer(ds_name=ds_name)\n",
    "    \n",
    "    if normals is not None:\n",
    "        pymevis.glCanvas.layers[-1].display_normals=True\n",
    "        pymevis.glCanvas.layers[-1].normal_scaling=25.0\n",
    "\n",
    "def save_snapshot(canvas, file_name=None):\n",
    "    if True:\n",
    "        pixel_size=None\n",
    "        \n",
    "        if file_name is None:\n",
    "            file_name = wx.FileSelector('Save current view as', wildcard=\"PNG files(*.png)|*.png\",\n",
    "                            flags=wx.FD_SAVE | wx.FD_OVERWRITE_PROMPT)\n",
    "        \n",
    "        if file_name:\n",
    "            snap = canvas.getIm(pixel_size, GL_RGB)\n",
    "            print(snap.dtype, snap.shape, snap.max())\n",
    "            if snap.ndim == 3:\n",
    "                img = PIL.Image.fromarray(snap.transpose(1, 0, 2))\n",
    "                #img = toimage(snap.transpose(1, 0, 2))\n",
    "            else:\n",
    "                img = PIL.Image.fromarray(snap.transpose())\n",
    "                #img = toimage(snap.transpose())\n",
    "            \n",
    "            img = img.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
    "            \n",
    "            if not file_name.endswith('.png'):\n",
    "                img.save('{}.png'.format(file_name))\n",
    "            else:\n",
    "                img.save('{}'.format(file_name))\n",
    "                \n",
    "def interior_points_from_sdf(sdf, r_max=1, centre=(0,0,0), dx_min=1, p=0.1, eps=0):\n",
    "    '''\n",
    "    Generate points from a signed distance function. Effectively does octree-like subdivision of the function domain to\n",
    "    assign points on a regular grid, then passes through a Monte-Carlo acceptance function to simulate labelling efficiency\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sdf : function\n",
    "        the signed distance function. Should be of the form dist = sdf(pts) where pts is a 3xN ndarray/\n",
    "    r_max: float\n",
    "        The maximum radius of the object (from centre)\n",
    "    centre : 3-tuple / array of float\n",
    "        The centre of the object\n",
    "    dx_min : float\n",
    "        The target side length of a voxel. Effectively a density parameter (density = 1/dx_min^3).\n",
    "    p : float\n",
    "        Monte-Carlo acceptance probability.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    verts : 3xN ndarray of fluorophore positions\n",
    "\n",
    "    '''\n",
    "    dx = 1.2 * r_max\n",
    "    \n",
    "    vx, vy, vz = [v.ravel() for v in np.mgrid[-1:2, -1:2, -1:2]]\n",
    "    \n",
    "    verts = dx * np.vstack([vx, vy, vz]) + np.array(centre)[:,None]\n",
    "#     print(verts.shape)\n",
    "    \n",
    "    c_offs = np.array(\n",
    "        [[-1, -1, -1], [1, -1, -1], [1, 1, -1], [-1, 1, -1], [-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1]])\n",
    "    #test_offs =\n",
    "    \n",
    "    while dx > dx_min:\n",
    "        dx /= 2.0\n",
    "        #test and discard.\n",
    "        corners = [verts + dx * c_offs[i][:, None] for i in range(8)]\n",
    "        corner_dists = [sdf(c) for c in corners] + [sdf(verts), ]\n",
    "#         print(corner_dists)\n",
    "        \n",
    "        #corner_dists = [sdf(verts),]\n",
    "        \n",
    "        #contains_points = np.abs(np.sum([np.sign(c) for c in corner_dists], axis=0)) < 9\n",
    "        # for some reason the sign test doesn't seem to work properly. Use a generous\n",
    "        # distance based test instead\n",
    "        contains_points = np.min([c for c in corner_dists], axis=0) < 2 * dx\n",
    "#         print(dx)\n",
    "#         print(corner_dists)\n",
    "        \n",
    "        verts = verts[:, contains_points]\n",
    "#         print(verts.shape)\n",
    "        \n",
    "        #subdivide\n",
    "        verts = np.concatenate([verts + dx * c_offs[i][:, None] for i in range(8)], axis=1)\n",
    "        #print(verts.shape)\n",
    "    \n",
    "    # because we use a fairly relaxed / conservative criterea for discarding above (which will\n",
    "    # effectively match the cell containing the surface AND it's neighbours)\n",
    "    # we perform a more stringent test on the final set of points.\n",
    "    corners = [verts + dx * c_offs[i][:, None] for i in range(8)]\n",
    "    corner_dists = [sdf(c) for c in corners]\n",
    "    \n",
    "    sv = sdf(verts)\n",
    "    contains_points = ((np.sum([np.sign(c) for c in corner_dists], axis=0) == -8) | (sv < dx)) & (sv < eps)\n",
    "    verts = verts[:, contains_points]\n",
    "    \n",
    "    #print(verts.shape)\n",
    "    \n",
    "    return verts[:, np.random.rand(verts.shape[1]) < p]\n",
    "\n",
    "def grad_sdf(pts, sdf, delta=0.1):\n",
    "    \"\"\"\n",
    "    Gradient of the signed distance function, calculated via central differences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pts : np.array\n",
    "        3 x N array of points on which we evaluate the gradient\n",
    "    sdf : function\n",
    "        Signed-distance function. Expects 3xN vector of x, y, z coordinates.\n",
    "    delta : float\n",
    "        Shift in gradient direction.\n",
    "    \"\"\"\n",
    "    d2 = delta/2.0\n",
    "    hx = np.array([d2,0,0])[:,None]\n",
    "    hy = np.array([0,d2,0])[:,None]\n",
    "    hz = np.array([0,0,d2])[:,None]\n",
    "    dx = (sdf(pts + hx) - sdf(pts - hx))/delta\n",
    "    dy = (sdf(pts + hy) - sdf(pts - hy))/delta\n",
    "    dz = (sdf(pts + hz) - sdf(pts - hz))/delta\n",
    "    \n",
    "    return dx, dy, dz\n",
    "\n",
    "def fullprint(*args, **kwargs):\n",
    "  from pprint import pprint\n",
    "  import numpy\n",
    "  opt = numpy.get_printoptions()\n",
    "  numpy.set_printoptions(threshold=numpy.inf)\n",
    "  pprint(*args, **kwargs)\n",
    "  numpy.set_printoptions(**opt)\n",
    "    \n",
    "def proj_u_onto_plane(u, n):\n",
    "    ''' \n",
    "    Input:\n",
    "        u: vector to be projected onto plane\n",
    "        n: vector normal to the plane\n",
    "    Output:\n",
    "        u_p: normalized projection of vector u onto plane with normal n\n",
    "    '''\n",
    "    n_norm = np.sqrt(sum(n**2))\n",
    "    proj_of_u_on_n = (np.dot(u, n)/n_norm**2)*n\n",
    "    u_p = u - proj_of_u_on_n\n",
    "    return u_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffc816-e306-46dd-8ad8-3aec660c17b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data except for axes which are more involved\n",
    "for dset in range(len(datadir)):\n",
    "    c_data = np.genfromtxt(datadir[dset], delimiter = ',')\n",
    "    clust = {\"count\": c_data[:,0], \"x\": c_data[:,1], \"y\": c_data[:,2], \"z\": c_data[:,3], \"gyrationRadius\": c_data[:,4], \n",
    "            \"median_abs_deviation\": c_data[:,5], \"sigma0\": c_data[:,9], \"sigma1\": c_data[:,10], \"sigma2\": c_data[:,11], \n",
    "            \"sigma_x\": c_data[:,12], \"sigma_y\": c_data[:,13], \"sigma_z\": c_data[:,14], \"anisotropy\": c_data[:,15], \n",
    "            \"theta\": c_data[:,16], \"phi\": c_data[:,17]}\n",
    "\n",
    "    #making save-folder if it doesn't exist (DON'T TOUCH THE NEXT 5 LINES)\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "    p = Path(savedir)\n",
    "    if not p.exists():\n",
    "        os.mkdir(savedir)\n",
    "    workdir = os.getcwd()\n",
    "\n",
    "    import pandas as pd\n",
    "    import copy\n",
    "\n",
    "    if 'check1' in locals():\n",
    "        del check1\n",
    "    if 'check2' in locals():\n",
    "        del check2\n",
    "    if 'x' in locals():\n",
    "        del x\n",
    "    if 'y' in locals():\n",
    "        del y\n",
    "    if 'z' in locals():\n",
    "        del z\n",
    "\n",
    "    # Initialize variables\n",
    "    csv_file = pd.read_csv(datadir[dset], sep=',', header=None)\n",
    "    clusto = {\"axis0\": np.copy(csv_file[6][1:].values), \"axis1\": np.copy(csv_file[7][1:].values), \n",
    "              \"axis2\": np.copy(csv_file[8][1:].values)}\n",
    "    clust['axis0'] = np.zeros((len(clust['count']),3))\n",
    "    clust['axis1'] = np.zeros((len(clust['count']),3))\n",
    "    clust['axis2'] = np.zeros((len(clust['count']),3))\n",
    "\n",
    "\n",
    "    # Convert 'axis0', 'axis1', and 'axis2' values to floats from strings\n",
    "    # axis0\n",
    "    for a in range(len(clusto[\"axis0\"])):\n",
    "        #print('a:',a)\n",
    "        if a > 0:\n",
    "            del x,y,z,check1,check2\n",
    "        if clusto['axis0'][a][2:4] == '[ ': \n",
    "            for b in range(1,len(clusto['axis0'][a])):\n",
    "                if clusto['axis0'][a][b] == ' ' and 'check1' not in locals():\n",
    "                    check1 = b\n",
    "                elif clusto['axis0'][a][b] == ' ' and 'check2' not in locals():\n",
    "                    x = float(clusto['axis0'][a][3:b])\n",
    "                    check2 = b\n",
    "                elif clusto['axis0'][a][b] == ' ' and clusto['axis0'][a][b-1] != ' ' and 'check2' in locals() and 'y' not in locals():             \n",
    "                    y = float(clusto['axis0'][a][check2:b])\n",
    "                    z = float(clusto['axis0'][a][b:-2])\n",
    "        elif clusto['axis0'][a][2] == '[' and clusto['axis0'][a][3] != ' ': \n",
    "            for b in range(1,len(clusto['axis0'][a])):\n",
    "                if clusto['axis0'][a][b] == ' ' and 'check1' not in locals():\n",
    "                    check1 = b\n",
    "                    x = float(clusto['axis0'][a][3:b])\n",
    "                elif clusto['axis0'][a][b] == ' ' and clusto['axis0'][a][b-1] != ' ' and 'check2' not in locals() and 'y' not in locals():# 'check2' not in locals():\n",
    "                    y = float(clusto['axis0'][a][check1:b])\n",
    "                    z = float(clusto['axis0'][a][b:-2])\n",
    "                    check2 = b\n",
    "        clust['axis0'][a] = np.array([x, y, z])\n",
    "    del check1, check2, x, y, z, a, b\n",
    "\n",
    "    # axis1\n",
    "    for c in range(len(clusto[\"axis1\"])):\n",
    "        if c > 0:\n",
    "            del x,y,z,check1,check2\n",
    "        if clusto['axis1'][c][2:4] == '[ ': \n",
    "            for d in range(1,len(clusto['axis1'][c])):\n",
    "                if clusto['axis1'][c][d] == ' ' and 'check1' not in locals():\n",
    "                    check1 = d\n",
    "                elif clusto['axis1'][c][d] == ' ' and 'check2' not in locals():\n",
    "                    x = float(clusto['axis1'][c][3:d])\n",
    "                    check2 = d\n",
    "                elif clusto['axis1'][c][d] == ' ' and clusto['axis1'][c][d-1] != ' ' and 'check2' in locals() and 'y' not in locals():             \n",
    "                    y = float(clusto['axis1'][c][check2:d])\n",
    "                    z = float(clusto['axis1'][c][d:-2])\n",
    "        elif clusto['axis1'][c][2] == '[' and clusto['axis1'][c][3] != ' ': \n",
    "            for d in range(1,len(clusto['axis1'][c])):\n",
    "                if clusto['axis1'][c][d] == ' ' and 'check1' not in locals():\n",
    "                    check1 = d\n",
    "                    x = float(clusto['axis1'][c][3:d])\n",
    "                elif clusto['axis1'][c][d] == ' ' and clusto['axis1'][c][d-1] != ' ' and 'check2' not in locals() and 'y' not in locals():# 'check2' not in locals():\n",
    "                    y = float(clusto['axis1'][c][check1:d])\n",
    "                    z = float(clusto['axis1'][c][d:-2])\n",
    "                    check2 = d\n",
    "        clust['axis1'][c] = np.array([x, y, z])\n",
    "    del check1, check2, x, y, z, c, d\n",
    "\n",
    "    # axis2\n",
    "    for e in range(len(clusto[\"axis2\"])):\n",
    "        if e > 0:\n",
    "            del x,y,z,check1,check2\n",
    "        if clusto['axis2'][e][2:4] == '[ ':\n",
    "            for f in range(1,len(clusto['axis2'][e])):\n",
    "                if clusto['axis2'][e][f] == ' ' and 'check1' not in locals():\n",
    "                    check1 = f\n",
    "                elif clusto['axis2'][e][f] == ' ' and 'check2' not in locals():\n",
    "                    x = float(clusto['axis2'][e][3:f])\n",
    "                    check2 = f\n",
    "                elif clusto['axis2'][e][f] == ' ' and clusto['axis2'][e][f-1] != ' ' and 'check2' in locals() and 'y' not in locals():             \n",
    "                    y = float(clusto['axis2'][e][check2:f])\n",
    "                    z = float(clusto['axis2'][e][f:-2])\n",
    "        elif clusto['axis2'][e][2] == '[' and clusto['axis2'][e][3] != ' ':\n",
    "            for f in range(1,len(clusto['axis2'][e])):\n",
    "                if clusto['axis2'][e][f] == ' ' and 'check1' not in locals():\n",
    "                    check1 = f\n",
    "                    x = float(clusto['axis2'][e][3:f])\n",
    "                elif clusto['axis2'][e][f] == ' ' and clusto['axis2'][e][f-1] != ' ' and 'check2' not in locals() and 'y' not in locals():# 'check2' not in locals():\n",
    "                    y = float(clusto['axis2'][e][check1:f])\n",
    "                    z = float(clusto['axis2'][e][f:-2])\n",
    "                    check2 = f\n",
    "        clust['axis2'][e] = np.array([x, y, z])\n",
    "\n",
    "    # Load and display points\n",
    "    pymevis.OpenFile(c_points[dset])\n",
    "\n",
    "    # define mesh sdf\n",
    "    from PYME.experimental.isosurface import distance_to_mesh\n",
    "\n",
    "    mesh_sdf = lambda pts: distance_to_mesh(pts.T, mesh)\n",
    "\n",
    "    # Load and display mesh\n",
    "    from PYME.experimental._triangle_mesh import TriangleMesh\n",
    "    from PYME.LMVis.layers.mesh import TriangleRenderLayer\n",
    "\n",
    "    mesh = TriangleMesh.from_stl(mesh_fn[dset])\n",
    "\n",
    "    mesh_name = pipeline.new_ds_name('surf')\n",
    "    pipeline.recipe.namespace[mesh_name] = mesh\n",
    "    layer = TriangleRenderLayer(pipeline, dsname=mesh_name, method='wireframe', cmap = 'SolidCyan')\n",
    "    pymevis.add_layer(layer)\n",
    "\n",
    "    # grab the bounding box\n",
    "    mesh_bbox = pymevis.glCanvas.layers[-1]._bbox\n",
    "\n",
    "    # Load and display skeleton (this is replacing the skeleton creation within the script approach because\n",
    "    # it takes so long to make the skeleton. Better to do it once and then load it in for analyses\n",
    "\n",
    "    from PYME.experimental._triangle_mesh import TriangleMesh\n",
    "    from PYME.LMVis.layers.mesh import TriangleRenderLayer\n",
    "\n",
    "    mesh = TriangleMesh.from_stl(skelly[dset])\n",
    "\n",
    "    mesh_name = pipeline.new_ds_name('skeleton')\n",
    "    pipeline.recipe.namespace[mesh_name] = mesh\n",
    "    layer = TriangleRenderLayer(pipeline, dsname=mesh_name, method='wireframe', cmap = 'SolidMagenta')\n",
    "    pymevis.add_layer(layer)\n",
    "\n",
    "    # grab the bounding box\n",
    "    mesh_bbox = pymevis.glCanvas.layers[-1]._bbox\n",
    "\n",
    "    # Import ExtractTableChannel Recipe\n",
    "    from PYME.recipes.localisations import ExtractTableChannel\n",
    "    recipe = pipeline.recipe\n",
    "    # Extract Rtn4 points as 'Rtn4' DataSource\n",
    "    recipe.add_modules_and_execute([ExtractTableChannel(recipe, inputName = 'filtered_localizations', outputName = 'Rtn4',\n",
    "                                                        channel = Rtn4_chan)])\n",
    "\n",
    "    # Select simulated DataSource\n",
    "    pipeline.selectDataSource('Rtn4')\n",
    "\n",
    "    # Calculate distance from simulated points to surface\n",
    "    from PYME.recipes.surface_fitting import DistanceToMesh\n",
    "    recipe = pipeline.recipe\n",
    "    recipe.add_modules_and_execute([DistanceToMesh(recipe, input_mesh = 'surf0', input_points = 'Rtn4', output = 'Rtn4_filt')])\n",
    "\n",
    "    # Select simulated datasource that now has the distance_to_surf0 values associated with it\n",
    "    pipeline.selectDataSource('Rtn4_filt')\n",
    "\n",
    "    # Dictionary with info about what filter to use and what values\n",
    "    filt_dict_rtn = {'distance_to_surf0': [low_filt,high_filt]}\n",
    "\n",
    "    # Use PYME FilterTable to filter by distance to mesh (SDF) using low_filt and high_filt variables\n",
    "    from PYME.recipes.tablefilters import FilterTable\n",
    "    recipe.add_modules_and_execute([FilterTable(recipe, inputName = 'Rtn4_filt', filters = filt_dict_rtn, \n",
    "                                                outputName = 'sdf_filtered_Rtn4')])\n",
    "\n",
    "    # Select the simulate points that passed the SDF filter above\n",
    "    pipeline.selectDataSource('sdf_filtered_Rtn4')\n",
    "\n",
    "    # Extract x,y,z coordinates for simulated points\n",
    "    x_rtn = pipeline['x']\n",
    "    y_rtn = pipeline['y']\n",
    "    z_rtn = pipeline['z']\n",
    "\n",
    "    # Merge x,y,z coordinates into one variable 'points_rtn'\n",
    "    points_rtn = np.c_[x_rtn.ravel(),y_rtn.ravel(),z_rtn.ravel()]\n",
    "\n",
    "    # Import cKDTree function from SciPy and use it on the skeleton\n",
    "    pipeline.selectDataSource('skeleton0')\n",
    "    d_skelly = pipeline.selectedDataSource\n",
    "    orig_skeleton = d_skelly._vertices['position'][d_skelly._vertices['halfedge']!=-1]\n",
    "    from scipy.spatial import cKDTree\n",
    "    tree_orig = cKDTree(orig_skeleton)\n",
    "\n",
    "    # Move each vertex to the average position of all of its neighbors within a 'ball_r' radius\n",
    "    # Also trim out vertices that have a # of nearest neighbors > than max_nn (these are the q-tip looking spots)\n",
    "    # This doesn't make the problem areas better, it just cuts them out entirely\n",
    "    from collections import OrderedDict\n",
    "    skeleton = orig_skeleton\n",
    "    bad_inds = []\n",
    "    a_ind = tree_orig.query_ball_point(skeleton, ball_r)\n",
    "    for trim in range(len(a_ind)):\n",
    "        skeleton[trim] = np.mean(skeleton[a_ind[trim]],axis=0)\n",
    "        if len(a_ind[trim]) > max_nn:\n",
    "            bad_inds.append(a_ind[trim])\n",
    "\n",
    "    flat_bad_inds = [element for sublist in bad_inds for element in sublist]\n",
    "    flat_unique = list(OrderedDict.fromkeys(flat_bad_inds))\n",
    "    skeleton = np.delete(skeleton, flat_unique, axis=0)\n",
    "\n",
    "    # Make KDTree based on the mean skeleton\n",
    "    mean_tree_skeleton = cKDTree(skeleton)\n",
    "\n",
    "    # Find the closest neighbor that is at least 'min_dist' away from point being queried.\n",
    "    nneigh_ind = np.zeros([len(skeleton),1])\n",
    "    nneigh_dist = np.zeros([len(skeleton),1])\n",
    "    for aa in range(len(skeleton)):\n",
    "        dist, ind = mean_tree_skeleton.query(skeleton[aa], k=len(skeleton), distance_upper_bound=max_dist*2)\n",
    "        for ab in range(len(dist)):\n",
    "            if dist[ab] > min_dist:\n",
    "                nneigh_ind[aa] = ind[ab]\n",
    "                nneigh_dist[aa] = dist[ab]\n",
    "                break\n",
    "\n",
    "    # Calculate vectors pointing from each point to its nearest neighbor that is at least 'min_dist' away.\n",
    "    skel_vecs = np.zeros([len(skeleton),3])\n",
    "    bad_skel = []\n",
    "    for ac in range(len(skeleton)):\n",
    "        if nneigh_ind[ac] >= len(skeleton):\n",
    "            bad_skel.append(ac)\n",
    "        else:\n",
    "            vec = skeleton[ac] - skeleton[int(nneigh_ind[ac][0])]\n",
    "            skel_vecs[int(ac)] = vec\n",
    "    bad_skel = np.asarray(bad_skel)\n",
    "    skeleton = np.delete(skeleton, bad_skel, axis=0)\n",
    "    nneigh_dist = np.delete(nneigh_dist, bad_skel, axis=0)\n",
    "    nneigh_ind = np.delete(nneigh_ind, bad_skel, axis=0)\n",
    "    skel_vecs = np.delete(skel_vecs, bad_skel, axis=0)\n",
    "\n",
    "    del mean_tree_skeleton\n",
    "    mean_tree_skeleton = cKDTree(skeleton)\n",
    "\n",
    "    # Normalize\n",
    "    skel_dist_mag = np.c_[nneigh_dist.ravel(),nneigh_dist.ravel(),nneigh_dist.ravel()]\n",
    "    vecs_hat = skel_vecs/skel_dist_mag\n",
    "\n",
    "    # Add those vectors to the skeleton in the GUI\n",
    "    # add_ds_from_Nx3(skeleton, pipeline, pymevis, ds_name=f'nn-mean-skel-{min_dist}nm', normals=vecs_hat)\n",
    "\n",
    "    # skel_dist = distance from each Rtn4 point to closest skeleton point; skel_ind = index of the closest point in 'skeleton'\n",
    "    skel_dist_rtn, skel_ind_rtn = mean_tree_skeleton.query(points_rtn, k=1)\n",
    "\n",
    "    ############################# Plot angles of centers of clusters to skeleton #############################\n",
    "\n",
    "    # map centers of clusters to 'centers' as xyz coordinates\n",
    "    centers = np.zeros([len(clust['x']),3])\n",
    "    for g in range(len(clust['x'])):\n",
    "        #centers.append([clust['x'][g],clust['y'][g],clust['z'][g]])\n",
    "        centers[g] = [clust['x'][g],clust['y'][g],clust['z'][g]]\n",
    "\n",
    "    # determine closest skeleton point to each cluster center\n",
    "    skel_dist_cent, skel_ind_cent = mean_tree_skeleton.query(centers, k=1)\n",
    "\n",
    "    # vector from 1st nearest neighbor to Rtn cluster center\n",
    "    v_cent = skeleton[skel_ind_cent]-centers\n",
    "\n",
    "    # make skel_dist an [n, 3] array to match v_cent\n",
    "    skel_dist_mag_cent = np.c_[skel_dist_cent.ravel(),skel_dist_cent.ravel(),skel_dist_cent.ravel()]\n",
    "\n",
    "    # normalized/unit vector pointing from skeleton to Rtn cluster center point (divide each part of the vector by magnitidue of vector)\n",
    "    vp_cent = v_cent/skel_dist_mag_cent #was v_cent_hat\n",
    "\n",
    "    # Calculate vector rejections to use for angle analysis\n",
    "    vecs_hat_ind = vecs_hat[skel_ind_cent] #only relevant skeleton vectors\n",
    "    v_cent = []\n",
    "    v_cent_hat = []\n",
    "    for vrej in range(len(vp_cent)):\n",
    "        v_temp = vp_cent[vrej]-vecs_hat_ind[vrej]*(np.dot(vp_cent[vrej],vecs_hat_ind[vrej])/np.linalg.norm(vecs_hat_ind[vrej]))\n",
    "        if vrej == 6:\n",
    "            print(v_temp)\n",
    "        v_cent.append(v_temp)\n",
    "        v_cent_hat_temp = v_temp/np.linalg.norm(v_temp)\n",
    "        v_cent_hat.append(v_cent_hat_temp)\n",
    "    v_cent = np.asarray(v_cent)\n",
    "    v_cent_hat = np.asarray(v_cent_hat)\n",
    "\n",
    "    # now let's construct the frame of reference\n",
    "    # Z-direction unit vector\n",
    "    zdir = np.array([0,0,1])\n",
    "\n",
    "    # pick dir along skeleton axis as first vector in frame\n",
    "    # skeleton axis vectors of skeleton points that are closest to each Rtn4 cluster center\n",
    "    frame0_cent = vecs_hat[skel_ind_cent]\n",
    "\n",
    "    # component of z not in the direction of e0 or portion of Z-dir that is orthogonal to frame0_cent\n",
    "    frame1_cent = zdir[None,:] - frame0_cent*(frame0_cent*zdir[None,:]).sum(1)[:,None]\n",
    "\n",
    "    # orthogonal to other two vectors in the frame\n",
    "    frame2_cent = np.cross(frame0_cent,frame1_cent,axis=1)\n",
    "\n",
    "    # make them unit vectors (vector divided its magnitude)\n",
    "    frame1_cent_norm = frame1_cent/np.linalg.norm(frame1_cent,axis=1)[:,None]\n",
    "    frame2_cent_norm = frame2_cent/np.linalg.norm(frame2_cent,axis=1)[:,None]\n",
    "\n",
    "    # Determine angles_rtn between z-direction and \n",
    "    angles_cent = np.arccos((v_cent_hat*frame1_cent_norm).sum(1))  # this works because frame1_rtn is also normalized (unit length=1)\n",
    "\n",
    "    # Add layer of center points with normals set as the vectors that point to closest part of the skeleton\n",
    "    add_ds_from_Nx3(centers, pipeline, pymevis, 'cluster-centers', normals=clust['axis0'])\n",
    "\n",
    "    # Calculate handedness of angles\n",
    "    # data_dict[name_list[ii]+'_angles_'+str(jj)] = data_list[ii]['angles'][jj]\n",
    "    # data_dict[name_list[ii]+'_sim_angles_'+str(jj)] = data_list[ii]['sim_angles'][jj]\n",
    "    skel_vecs = vecs_hat_ind\n",
    "    loc_vecs = v_cent_hat\n",
    "    hand = np.cross(skel_vecs,loc_vecs)\n",
    "    zhand = hand[:,2]\n",
    "    hand_bool = np.ones(len(zhand))\n",
    "    for neg in range(len(zhand)):\n",
    "        if zhand[neg] >= 0:\n",
    "            continue\n",
    "        elif zhand[neg] < 0:\n",
    "            hand_bool[neg] = hand_bool[neg] * -1\n",
    "\n",
    "    angles_cent = angles_cent * hand_bool\n",
    "    del skel_vecs, loc_vecs, hand, zhand, hand_bool\n",
    "\n",
    "    # Import ExtractTableChannel Recipe\n",
    "    from PYME.recipes.localisations import ExtractTableChannel\n",
    "    recipe = pipeline.recipe\n",
    "    # Extract cluster center point\n",
    "\n",
    "    # Select simulated DataSource\n",
    "    pipeline.selectDataSource('cluster-centers')\n",
    "\n",
    "    # Calculate distance from simulated points to surface\n",
    "    from PYME.recipes.surface_fitting import DistanceToMesh\n",
    "    recipe = pipeline.recipe\n",
    "    recipe.add_modules_and_execute([DistanceToMesh(recipe, input_mesh = 'surf0', input_points = 'cluster-centers',\n",
    "                                                   output = 'centers_sdf')])\n",
    "\n",
    "    # Select simulated datasource that now has the distance_to_surf0 values associated with it\n",
    "    pipeline.selectDataSource('centers_sdf')\n",
    "\n",
    "    # Dictionary with info about what filter to use and what values\n",
    "    filt_dict_rtn = {'distance_to_surf0': [low_filt,high_filt]}\n",
    "\n",
    "    # Use PYME FilterTable to filter by distance to mesh (SDF) using low_filt and high_filt variables\n",
    "    from PYME.recipes.tablefilters import FilterTable\n",
    "    recipe.add_modules_and_execute([FilterTable(recipe, inputName = 'centers_sdf', filters = filt_dict_rtn, \n",
    "                                                outputName = 'sdf_filtered_centers')])\n",
    "\n",
    "    # Select the simulate points that passed the SDF filter above\n",
    "    pipeline.selectDataSource('sdf_filtered_centers')\n",
    "\n",
    "    # Filter data\n",
    "\n",
    "    # Determine how far each cluster center is from the membrane surface so we can filter out those\n",
    "    # that are too far away\n",
    "    pipeline.selectDataSource('surf0')\n",
    "    surf_d = pipeline.selectedDataSource\n",
    "    surf_verts = surf_d._vertices['position'][surf_d._vertices['halfedge']!=-1]\n",
    "    surf_norms = surf_d._vertices['normal']\n",
    "    from scipy.spatial import cKDTree\n",
    "    tree_surf = cKDTree(surf_verts)\n",
    "    surf_dist, surf_ind = tree_surf.query(centers, k=1)\n",
    "    skel_cent_dist, skel_cent_ind = mean_tree_skeleton.query(centers, k=1)\n",
    "\n",
    "    # Create filters to filter out clusters that are too far from the skeleton and that are less than clust_min in size\n",
    "    sdf_filt = skel_cent_dist < high_filt\n",
    "    size_filt = clust['count'] >= clust_min\n",
    "    # create filter of aspect ratio of clusters (determined by standard deviation)\n",
    "    major = clust['sigma0']\n",
    "    minor = clust['sigma1']\n",
    "    #asprat = major/minor\n",
    "    #asprat_filt = asprat >= asprat_thresh\n",
    "\n",
    "    #total_filt = sdf_filt * size_filt * asprat_filt\n",
    "    total_filt = sdf_filt * size_filt\n",
    "\n",
    "    # Apply filter\n",
    "    # filter by aspect ratio of clusters (determined by standard deviation)\n",
    "    frame0_cent_filt = frame0_cent[total_filt]\n",
    "    frame1_cent_filt = frame1_cent_norm[total_filt]\n",
    "    frame2_cent_filt = frame2_cent_norm[total_filt]\n",
    "    clust_filt = clust['axis0'][total_filt]\n",
    "    centers_filt = centers[total_filt]\n",
    "    angles_cent_filt = angles_cent[total_filt]\n",
    "    v_cent_hat_filt = v_cent_hat[total_filt]\n",
    "\n",
    "    from numpy import pi\n",
    "    # 4. clusters whose axes are tangent to surface in any direction (360 degrees) and positioned as real data\n",
    "\n",
    "    # Vectors can probably just point from each vertex to the closest vertex. That should be pretty random\n",
    "    # and tangent\n",
    "    # positions = cluster_center_positions\n",
    "    # vectors = tangent_to_surface_and_any_direction\\\n",
    "    # followed advice from https://stackoverflow.com/questions/71160423/how-to-sample-points-in-3d-in-python-with-origin-and-normal-vector\n",
    "\n",
    "    # parameters for this simulation\n",
    "    r = 1 # radius of points sampled in the circle on the plane (probably leave as 1 always)\n",
    "    v_num = 50 # number of vectors desired (evenly spaced around the circle)\n",
    "\n",
    "    # equations for making the vectors\n",
    "    rho = np.linspace(0, 2*np.pi, v_num)\n",
    "    x = np.cos(rho) * r\n",
    "    y = np.sin(rho) * r\n",
    "    z = np.zeros(rho.shape)\n",
    "    # positions of simulated clusters\n",
    "    arot_pos = centers_filt\n",
    "    # establish initial vectors\n",
    "    arot_surf_dist, arot_surf_ind = tree_surf.query(arot_pos, k=1)\n",
    "    arot_skel_dist, arot_skel_ind = mean_tree_skeleton.query(arot_pos, k=1)\n",
    "    arot_skel_vec = arot_pos - skeleton[arot_skel_ind]\n",
    "    arot_vecs = np.cross(vecs_hat[arot_skel_ind], arot_skel_vec)\n",
    "    arot_tub = vecs_hat[arot_skel_ind]\n",
    "\n",
    "    # Create vectors in a circle in the plane perpendicular to the vector that points from cluster center to skeleton\n",
    "    f_all = []\n",
    "    for bd in range(len(arot_pos)):\n",
    "        p1 = arot_pos[bd]\n",
    "        n = arot_skel_vec[bd] # vector normal to the plane\n",
    "        #pp = arot_vecs[bd] #vector orthogonal to normal\n",
    "        nabs = np.absolute(n)\n",
    "        indices = (-n).argsort()[:3]\n",
    "        v = np.zeros(3)\n",
    "        v[indices[1]] = -n[indices[0]]\n",
    "        v[indices[0]] = n[indices[1]]\n",
    "        v[indices[2]] = 0\n",
    "        u = np.cross(n,v)\n",
    "        #normalize vectors\n",
    "        v_norm = v/np.linalg.norm(v)\n",
    "        u_norm = u/np.linalg.norm(u)\n",
    "        f = []\n",
    "        for be in range(len(rho)):\n",
    "            circ_p = p1 + r * v_norm * np.cos(rho[be]) + r * u_norm * np.sin(rho[be])\n",
    "            circ_vec = p1-circ_p\n",
    "            f.append(circ_vec/np.linalg.norm(circ_vec))\n",
    "        f = np.asarray(f)\n",
    "        f_all.append(f)\n",
    "    f_all = np.asarray(f_all)\n",
    "\n",
    "    del u\n",
    "    # #Add the positions with each of the simulated cluster vectors (the number of which is equal to 'rho'-1)\n",
    "    # for bf in range(len(rho)-1):\n",
    "    #     name = 'all-rots-' + str(bf)\n",
    "    #     add_ds_from_Nx3(arot_pos, pipeline, pymevis, name, normals=f_all[:,bf])\n",
    "\n",
    "    # Calculate portion of Z-dir that is orthogonal to frame0_cent (z-axis of the tubule accroding to tubule axis)\n",
    "    arot_z = zdir[None,:] - vecs_hat[arot_skel_ind]*(vecs_hat[arot_skel_ind]*zdir[None,:]).sum(1)[:,None]\n",
    "\n",
    "    # project simulated cluster vectors onto xy-ish axis of tubules\n",
    "    proj_arot_all = []\n",
    "    for zy in range(len(f_all)):\n",
    "        proj_arot = []\n",
    "        for zz in range(len(rho)-1):\n",
    "            # u = f_all[zy][zz]\n",
    "            # n = arot_z[zy]\n",
    "            # n_norm = np.sqrt(sum(n**2))\n",
    "            # proj = u-(np.dot(u,n)/n_norm**2)*n\n",
    "            # proj_arot.append(proj)\n",
    "            proj_arot.append(proj_u_onto_plane(f_all[zy][zz], arot_z[zy]))\n",
    "        proj_arot = np.asarray(proj_arot)\n",
    "        proj_clust_norm = proj_arot/np.linalg.norm(proj_arot,axis=1)[:,None]\n",
    "        proj_arot_all.append(proj_clust_norm)\n",
    "    proj_arot_all = np.asarray(proj_arot_all)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate angle between simulated points/vectors and tubule axis/tubule z-axis\n",
    "    arot_tangs_all = []\n",
    "    arot_ptangs_all = []\n",
    "    arot_zangs_all = []\n",
    "    for bi in range(len(rho)-1):\n",
    "        arot_tangs = np.zeros(len(arot_pos))\n",
    "        arot_ptangs = np.zeros(len(arot_pos))\n",
    "        arot_zangs = np.zeros(len(arot_pos))\n",
    "        for bg in range(len(arot_pos)):\n",
    "            # Take arccos of the dot product to get the angle out\n",
    "            arot_tangs[bg] = np.arccos(np.dot(arot_tub[bg],f_all[:,bi][bg]))\n",
    "            arot_ptangs[bg] = np.arccos(np.dot(arot_tub[bg],proj_arot_all[:,bi][bg]))\n",
    "            arot_zangs[bg] = np.arccos(np.dot(arot_z[bg],f_all[:,bi][bg]))\n",
    "        # remove NaNs that occur for some reason (something about invalid value for arccos but I don't understand why)\n",
    "        # it shouldn't matter though since there are so many points anyways and they are all just going to be 0 anyways\n",
    "        # filter out the same ones for z-axis even though that shouldn't have issues, just to be consistent\n",
    "        arot_zangs = arot_zangs[~np.isnan(arot_tangs)]\n",
    "        arot_tangs = arot_tangs[~np.isnan(arot_tangs)]\n",
    "        arot_ptangs = arot_ptangs[~np.isnan(arot_tangs)]\n",
    "        arot_tangs_all.append(arot_tangs)\n",
    "        arot_ptangs_all.append(arot_ptangs)\n",
    "        arot_zangs_all.append(arot_zangs)\n",
    "    arot_tangs_all = np.asarray(arot_tangs_all)\n",
    "    flat_arot_tangs = [element for sublist in arot_tangs_all for element in sublist]\n",
    "    flat_arot_tangs = np.asarray(flat_arot_tangs)\n",
    "\n",
    "    arot_ptangs_all = np.asarray(arot_ptangs_all)\n",
    "    flat_arot_ptangs = [element for sublist in arot_ptangs_all for element in sublist]\n",
    "    flat_arot_ptangs = np.asarray(flat_arot_ptangs)\n",
    "\n",
    "    arot_zangs_all = np.asarray(arot_zangs_all)\n",
    "    flat_arot_zangs = [element for sublist in arot_zangs_all for element in sublist]\n",
    "    flat_arot_zangs = np.asarray(flat_arot_zangs)\n",
    "    # convert from radians to degrees\n",
    "    arot_tdeg = flat_arot_tangs * (180/pi)\n",
    "    arot_ptdeg = flat_arot_ptangs * (180/pi)\n",
    "    arot_zdeg = flat_arot_zangs * (180/pi)\n",
    "\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "    ax.scatter(proj_arot_all[0][:,0],proj_arot_all[0][:,1],proj_arot_all[0][:,2],label='proj')\n",
    "    ax.scatter(0,0,0,label='zero')\n",
    "    ax.scatter(1,0,0,label='x')\n",
    "    ax.scatter(0,1,0,label='y')\n",
    "    ax.scatter(f_all[0][:,0],f_all[0][:,1],f_all[0][:,2],label='clust')\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(.6, .6, 0.5, 0.5))\n",
    "    #ax.set_xlim([-1,1])\n",
    "    #ax.set_ylim([-1,1])\n",
    "    ax.set_zlim([-1,1])\n",
    "\n",
    "    # list of hex color options that are color-blind friendly\n",
    "    CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                      '#f781bf', '#a65628', '#984ea3',\n",
    "                      '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "    # Create histogram of the angles from Rtn4 cluster centers to nearest skeleton point\n",
    "    import matplotlib.pyplot as plt\n",
    "    from numpy import pi\n",
    "    plt.close(fig=None)\n",
    "\n",
    "    n_cent, bins_cent, patches_cent = plt.hist(x=angles_cent[total_filt],bins=16, alpha=1, rwidth=0.85, density=True, color=CB_color_cycle[0], \n",
    "                                               range=(0,pi), label='Rtn4 Cluster Centers')\n",
    "    plt.xlabel('Angle between cluster centers and tubule axes')\n",
    "    plt.ylabel('Normalized # of events')\n",
    "    plt.legend()\n",
    "    # cent_save = savedir + '\\\\angles_of_cluster_centers' + ver + '.png'\n",
    "    # plt.savefig(cent_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "    #         orientation='portrait', papertype=None, format=None,\n",
    "    #         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "    #         frameon=None, metadata=None)\n",
    "\n",
    "    \"\"\"\n",
    "    =======================\n",
    "    Histogram on polar axis\n",
    "    =======================\n",
    "\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from numpy import pi\n",
    "\n",
    "    # Import note:\n",
    "    # Make mirror of data (currently all angles are output as positive because there's no orientation in regards to which\n",
    "    # side of the tubule the cluster center point is)\n",
    "\n",
    "    # angles_cent_neg = -angles_cent_filt + 2*pi\n",
    "    # angles_cent_all = np.concatenate((angles_cent_filt,angles_cent_neg), axis=0)\n",
    "    fig = plt.figure(figsize=[12,12])\n",
    "    ax = plt.subplot(111, projection='polar')\n",
    "    hist = ax.hist(x=angles_cent_filt,bins=32, alpha=1, rwidth=0.85, density=True, color=CB_color_cycle[0], \n",
    "                   label='Rtn4 Cluster Centers')\n",
    "    ax.set_rlabel_position(0)  # Move radial labels away from plotted line\n",
    "    #ax.set_theta_zero_location(\"N\")\n",
    "    #ax.set_rlabel_position(180)  # Move radial labels away from plotted line\n",
    "    ax.set_theta_zero_location(\"N\")\n",
    "    plt.xlabel('Normalized # of events')\n",
    "    plt.legend()\n",
    "    plt.legend(loc='best', bbox_to_anchor=(1.2, 1.15))\n",
    "    polar_cent_save = savedir + '\\\\polar_angles_of_cluster_centers' + d_name[dset] + '_' + ver + '.png'\n",
    "    plt.savefig(polar_cent_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "            orientation='portrait', papertype=None, format=None,\n",
    "            transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "            frameon=None, metadata=None)\n",
    "\n",
    "    # 3D scatter plot of vectors that are used to calculate angles (sanity check)\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import matplotlib.pyplot as plt\n",
    "    CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                      '#f781bf', '#a65628', '#984ea3',\n",
    "                      '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "    # tubule z-axis\n",
    "    x = frame1_cent_filt[:,0]\n",
    "    y = frame1_cent_filt[:,1]\n",
    "    z = frame1_cent_filt[:,2]\n",
    "    # random uniform vectors along unit circle\n",
    "    # x2 = con_r_norm[:,0]\n",
    "    # y2 = con_r_norm[:,1]\n",
    "    # z2 = con_r_norm[:,2]\n",
    "    # tubule axis vectors\n",
    "    x3 = frame0_cent_filt[:,0]\n",
    "    y3 = frame0_cent_filt[:,1]\n",
    "    z3 = frame0_cent_filt[:,2]\n",
    "    # cluster axis vectors\n",
    "    x4 = clust_filt[:,0]\n",
    "    y4 = clust_filt[:,1]\n",
    "    z4 = clust_filt[:,2]\n",
    "    ax.scatter(x,y,z,c=CB_color_cycle[0],alpha=0.5,label='Tubule z-axis')\n",
    "    # ax.scatter(x2,y2,z2,c=CB_color_cycle[1],alpha=0.5,label='Random')\n",
    "    ax.scatter(x3,y3,z3,c=CB_color_cycle[5],alpha=0.5,label='Tubule axis')\n",
    "    ax.scatter(x4,y4,z4,c=CB_color_cycle[2],alpha=0.5,label='Cluster major axis')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(.6, .6, 0.5, 0.5))\n",
    "    scatter3d_save = savedir + '\\\\3D_scatter_vectors' + d_name[dset] + '_' + ver + '.png'\n",
    "    plt.savefig(scatter3d_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "            orientation='portrait', papertype=None, format=None,\n",
    "            transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "            frameon=None, metadata=None)\n",
    "\n",
    "    ################### Calculate angle between Rtn4 cluster principle axis and skeleton axis ###################\n",
    "\n",
    "    # Making a list of random angles as a control\n",
    "    # Note: one might think that drawing random numbers from a uniform distribution is how you get a uniform \n",
    "    # distribution of vectors around a unit sphere, but this will actually result in the vectors pointing to \n",
    "    # spots bunched at the poles of the sphere. Instead, a gaussian/normal distribution should be used.\n",
    "    # See: https://mathworld.wolfram.com/SpherePointPicking.html for a more in-depth explanation\n",
    "\n",
    "    d_len = len(frame0_cent_filt)\n",
    "    con_r = np.random.default_rng().normal(size=[d_len, 3])\n",
    "    con_r_norm = con_r/np.linalg.norm(con_r,axis=1)[:,None]\n",
    "\n",
    "    # project cluster vectors onto the xy-ish plane of the tubule before calculating the angle between the\n",
    "    # cluster vector and the tubule axis\n",
    "    proj_clust = []\n",
    "    for z in range(len(clust_filt)):\n",
    "\n",
    "        proj_clust.append(proj_u_onto_plane(clust_filt[z], frame1_cent_filt[z]))\n",
    "\n",
    "        # u = clust_filt[z]\n",
    "        # n = frame1_cent_filt[z]\n",
    "        # n_norm = np.sqrt(sum(n**2))\n",
    "        # proj_clust.append(u-(np.dot(u,n)/n_norm**2)*n)\n",
    "\n",
    "        #proj_clust.append((np.dot(clust_filt[z],frame1_cent_filt[z])/(np.linalg.norm(frame1_cent_filt[z]))**2)*frame1_cent_filt[z])\n",
    "    proj_clust = np.asarray(proj_clust)\n",
    "    proj_clust_norm = proj_clust/np.linalg.norm(proj_clust,axis=1)[:,None]\n",
    "\n",
    "    # Calculate dot product one cell at a time\n",
    "    c_tangs = np.zeros(len(frame0_cent_filt))\n",
    "    cp_tangs = np.zeros(len(frame0_cent_filt))\n",
    "    c_dot = np.zeros(len(frame0_cent_filt))\n",
    "    c_zangs = np.zeros(len(frame0_cent_filt))\n",
    "    control2 = np.zeros(len(frame0_cent_filt))\n",
    "    zcon = np.zeros(len(frame0_cent_filt))\n",
    "    con_r_angs = np.zeros(len(frame0_cent_filt))\n",
    "    for i in range(len(frame0_cent_filt)):\n",
    "        # Take arccos of the dot product to get the angle out\n",
    "        c_tangs[i] = np.arccos(np.dot(frame0_cent_filt[i],clust_filt[i])) # not projected onto tubule xy plane\n",
    "        cp_tangs[i] = np.arccos(np.dot(frame0_cent_filt[i],proj_clust_norm[i])) # projected onto tubule xy plane\n",
    "        c_dot[i] = np.dot(frame0_cent_filt[i],clust_filt[i])\n",
    "        c_zangs[i] = np.arccos(np.dot(frame1_cent_filt[i],clust_filt[i]))\n",
    "        control2[i] = np.arccos(np.dot(frame2_cent_filt[i],clust_filt[i]))\n",
    "        zcon[i] = np.arccos(np.dot(zdir, clust_filt[i]))\n",
    "        con_r_angs[i] = np.arccos(np.dot(con_r_norm[i],clust_filt[i]))\n",
    "\n",
    "    # convert radians to degrees\n",
    "    c_tdeg = c_tangs * (180/pi)\n",
    "    cp_tdeg = cp_tangs * (180/pi)\n",
    "    c_zdeg = c_zangs * (180/pi)\n",
    "    con2_deg = control2 * (180/pi)\n",
    "    zcon_deg = zcon * (180/pi)\n",
    "    con_r_deg = con_r_angs * (180/pi)\n",
    "    # Plot the angles as a histogram (pi/2 would mean the cluster principle axis is orthogonal to the skeleton axis)\n",
    "    # (0 or pi would mean the cluster principle axis is parallel to the skeleton axis)\n",
    "    import matplotlib.pyplot as plt\n",
    "    from numpy import pi\n",
    "    plt.close(fig=None)\n",
    "    n_clust, bins_clust, patches_clust = plt.hist(x=c_tdeg,bins=24, alpha=0.5, rwidth=0.85, density=True, color='green', \n",
    "                                                  range=(0,180), label='Rtn4 clusters')\n",
    "    #x2 = (np.arange(np.min(bins_clust)+cents, np.max(bins_clust)+diff, diff) - cents)\n",
    "    #plt.plot(x2,np.sin(x2)/2)\n",
    "    plt.xlabel('Angle between cluster major axis and tubule axis')\n",
    "    plt.ylabel('Normalized # of events')\n",
    "    plt.legend()\n",
    "    clust_save = savedir + '\\\\angles_of_cluster-axes-degrees' + d_name[dset] + '_' + ver + '.png'\n",
    "    # plt.savefig(clust_save, dpi=300, facecolor='w', edgecolor='w',\n",
    "    #         orientation='portrait', papertype=None, format=None,\n",
    "    #         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "    #         frameon=None, metadata=None)\n",
    "\n",
    "    # Save a dictionary of counts, bins, and angles to cluster centers to combine experimental results later\n",
    "    cluster_output = {'c_tdeg': c_tdeg, 'cp_tdeg': cp_tdeg, 'c_zdeg': c_zdeg, 'arot_tdeg': arot_tdeg, \n",
    "                      'arot_zdeg': arot_zdeg, 'center_angles': angles_cent_filt}\n",
    "    save_output_file = savedir + '\\\\cluster_output_' + d_name[dset] + '_' + ver + '.npy'\n",
    "    np.save(save_output_file, cluster_output, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4620f64c-f9b5-4349-b2b2-1e2f49e3e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "ax.scatter(proj_clust_norm[:,0],proj_clust_norm[:,1],proj_clust_norm[:,2],label='proj')\n",
    "ax.scatter(0,0,0,label='zero')\n",
    "ax.scatter(1,0,0,label='x')\n",
    "ax.scatter(0,1,0,label='y')\n",
    "ax.scatter(clust_filt[:,0],clust_filt[:,1],clust_filt[:,2],label='clust')\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(.6, .6, 0.5, 0.5))\n",
    "\n",
    "#ax.scatter(clust_filt[:,0],clust_filt[:,1],clust_filt[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control histogram of \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import pi\n",
    "plt.close(fig=None)\n",
    "n_clust, bins_clust, patches_clust = plt.hist(x=c_zdeg,bins=12, alpha=0.25, rwidth=0.85, density=True, color=CB_color_cycle[0], \n",
    "                                              range=(0,180), label='Tubule z-axis')\n",
    "n_clust, bins_clust, patches_clust = plt.hist(x=c_tdeg,bins=12, alpha=0.25, rwidth=0.85, density=True, color=CB_color_cycle[1], \n",
    "                                              range=(0,180), label='Tubule axis')\n",
    "n_clust, bins_clust, patches_clust = plt.hist(x=con2_deg,bins=12, alpha=0.25, rwidth=0.85, density=True, color=CB_color_cycle[2], \n",
    "                                              range=(0,180), label='Perpindicular\\naxis control')\n",
    "n_clust, bins_clust, patches_clust = plt.hist(x=zcon_deg,bins=12, alpha=0.25, rwidth=0.85, density=True, color=CB_color_cycle[3], \n",
    "                                              range=(0,180), label='True Z-Axis\\n control')\n",
    "plt.xlabel('Angle between axes')\n",
    "plt.ylabel('Normalized # of events')\n",
    "plt.legend()\n",
    "control_save = savedir + '\\\\control_for_cluster-axes-degrees' + ver + '.png'\n",
    "# plt.savefig(control_save, dpi=300, facecolor='w', edgecolor='w',\n",
    "#         orientation='portrait', papertype=None, format=None,\n",
    "#         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "#         frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630e04d-bf39-4b72-83e1-e9e80336b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================================================\n",
    "Violin Plots of Angles between axes WITH CONTROLS\n",
    "=================================================\n",
    "used a lot of advice from: \n",
    "https://towardsdatascience.com/making-publication-quality-figures-in-python-part-iv-violin-plot-and-dendrogram-ed0bb8b23ddd\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from scipy.stats import ranksums\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import epps_singleton_2samp\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import wilcoxon\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "# Statistics\n",
    "from itertools import combinations\n",
    "# stats_list = [con_deg, c_deg, parcon_tdeg, parcon_zdeg, tang_tdeg, tang_zdeg, rtang_tdeg, rtang_zdeg,\n",
    "#              arot_tdeg, arot_zdeg]\n",
    "# stats_list = [c_tdeg, cp_tdeg, c_zdeg, arot_tdeg, arot_ptdeg, arot_zdeg, asph_tdeg, asph_ptdeg, asph_zdeg,\n",
    "#              ip_tdeg, ip_ptdeg, ip_zdeg]\n",
    "stats_list= [c_tdeg, arot_tdeg]\n",
    "# stats_all = np.zeros(len(stats_list),dtype=list)\n",
    "# stats_all[0] = ks_2samp(stats_list[0], stats_list[1])\n",
    "# stats_all[1] = ks_2samp(stats_list[1], stats_list[2])\n",
    "# stats_all[2] = ks_2samp(stats_list[0], stats_list[2])\n",
    "combo = list(combinations(range(len(stats_list)),2))\n",
    "stats_all = np.zeros(len(combo),dtype=list)\n",
    "for i in range(len(combo)):\n",
    "    stats_all[i] = ks_2samp(stats_list[combo[i][0]], stats_list[combo[i][1]])\n",
    "\n",
    "def get_whisker(tmp,dataset):\n",
    "    whisker = []\n",
    "    for quantile,data in zip(tmp,dataset):\n",
    "        data = np.array(data)\n",
    "        q1 = quantile[0]\n",
    "        median = quantile[1]\n",
    "        q3 = quantile[2]\n",
    "        iqr = q3 - q1\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        upper = np.clip(upper,q3,data.max())\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        lower = np.clip(lower,data.min(),q1)\n",
    "        whisker.append((upper,lower))\n",
    "    return whisker\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00','#a65628',\n",
    "                  '#f781bf', '#4daf4a',  '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "colors = ['#377eb8', '#377eb8', '#377eb8',\n",
    "          '#ff7f00', '#ff7f00', '#ff7f00',\n",
    "          '#4daf4a', '#4daf4a', '#4daf4a', \n",
    "         '#a65628', '#a65628', '#a65628']\n",
    "\n",
    "def stars(p):\n",
    "   if p < 0.0001:\n",
    "       return \"****\"\n",
    "   elif (p < 0.001):\n",
    "       return \"***\"\n",
    "   elif (p < 0.01):\n",
    "       return \"**\"\n",
    "   elif (p < 0.05):\n",
    "       return \"*\"\n",
    "   else:\n",
    "       return \"ns\"\n",
    "\n",
    "count = 0\n",
    "#all_sig = [con_deg,c_deg,con_r_deg]\n",
    "# xlabels = ['Rtn4-Z', 'Rtn4-T', 'Rand-Par-T', 'Rand-Par-Z', 'Rand-Tan-T', 'Rand-Tan-Z',\n",
    "#            'Real-Tan-T', 'Real-Tan-Z', 'Real-Any-T', 'Real-Any-Z']\n",
    "xlabels = ['Rtn4-T', 'Rtn4-Proj-T', 'Rtn4-Z', 'Real-Tan-Any-T', 'Real-Tan-Proj-T', 'Real-Tan-Any-Z', \n",
    "           'Real-Sph-T', 'Real-Sph-Proj-T', 'Real-Sph-Z', 'In-Plane-T', 'In-Plane-Proj-T', 'In-Plane-Z']\n",
    "tmp = [np.percentile(data,[25,50,75]) for data in stats_list]\n",
    "whisker = get_whisker(tmp,stats_list)\n",
    "positions = [1,1]#np.linspace(0,len(stats_list)-1,len(stats_list))#\n",
    "# fig,ax = plt.subplots(figsize=[12,12])\n",
    "# gs1 = GridSpec(8, 2, hspace=0, wspace=0.1)\n",
    "# vp = ax.violinplot(dataset=stats_list,positions=positions)\n",
    "fig = plt.figure(tight_layout=True)\n",
    "gs = GridSpec(1,8)\n",
    "ax = fig.add_subplot(gs[0,:])\n",
    "vp = ax.violinplot(dataset=stats_list,positions=positions)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_facecolor(colors[count])\n",
    "    pc.set_edgecolor('black')\n",
    "    count = count + 1\n",
    "    pc.set_linewidth(2)\n",
    "    pc.set_alpha(0.2)\n",
    "vp['cmaxes'].set_color('black')\n",
    "vp['cmins'].set_color('black')\n",
    "vp['cbars'].set_color('black')\n",
    "                      \n",
    "ax.scatter(positions, [quantile[1] for quantile in tmp],\n",
    "           marker='o', color='white',s=30,zorder=3)\n",
    "ax.vlines(positions, [quantile[0] for quantile in tmp],\n",
    "          [quantile[2] for quantile in tmp],\n",
    "          color='black',linestyle='-',lw=10)\n",
    "ax.vlines(positions,\n",
    "          [bound[0] for bound in whisker],\n",
    "          [bound[1] for bound in whisker],\n",
    "          color='black',linestyle='-',lw=2)\n",
    "plt.xlabel('Principle Axes')\n",
    "plt.ylabel('Degrees')\n",
    "plt.xticks(positions, xlabels)#('Tubule z-axis', 'Tubule axis', 'Random control'))\n",
    "# ax2 = fig.add_subplot(gs[0,:])\n",
    "# ax2.set_xlim([-1,len(stats_list)+1])\n",
    "# ax2.set_yticks([])\n",
    "# ax2.set_xticks([])\n",
    "#ax2.axis('off')\n",
    "count = 0\n",
    "#ann1 = np.linspace(0,len(stats_list)-1,len(stats_list))\n",
    "# while len(stats_list)/count > 1:\n",
    "#     ann = np.linspace(0,(len(stats_list)/2)-1,len(stats_list)/2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c87141-f9d0-4c43-b1cf-899e0635650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_list = [c_tdeg, c_zdeg, arot_tdeg, arot_zdeg] # [angles between cluster principle axis and tubule axis, angles between cluster principal axis and z-axis, angle between simulated clusters with principal axis in any possible direction tangent to membrane and the tubule axis, same but with z-axis] \n",
    "data_list = [c_tdeg, arot_tdeg]\n",
    "#data_names = [u'\\u2220 \\u03C4 Real', u'\\u2220 \\u03C4 Sim']\n",
    "deg_range = [0,180]\n",
    "all_counts = []\n",
    "all_bins = []\n",
    "fig = plt.figure(tight_layout=True)\n",
    "for da in range(len(data_list)):\n",
    "    count, bins = np.histogram(data_list[da], bins=181, density=True, range=deg_range)\n",
    "    all_counts.append(count)\n",
    "    all_bins.append(bins)\n",
    "    plt.step(bins[:-1], count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f53d62-c393-4e01-a212-fd3129a7ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cent_hat_filt[ninety_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b931232-4ab6-40bd-8e83-c956e93960a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninety_filt = c_tdeg == 90\n",
    "ninety_centers = centers_filt[ninety_filt]\n",
    "add_ds_from_Nx3(ninety_centers, pipeline, pymevis, 'ninety-centers', normals=v_cent_hat_filt[ninety_filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e5180-2d2f-432e-abd5-302f04e3a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_color_cycle = ['#377eb8', '#ff7f00','#a65628',\n",
    "                  '#f781bf', '#4daf4a',  '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "fig, axs = plt.subplots(2,1, figsize=(12,36))\n",
    "axs[0].step(all_bins[0][:-1], all_counts[0], color=CB_color_cycle[1], linewidth=3, label='Rtn4-tubule')\n",
    "axs[0].step(all_bins[2][:-1], all_counts[2], color=CB_color_cycle[6], linewidth=3, label='Sim-tubule')\n",
    "axs[0].set_ylim([0,0.015])\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[1].step(all_bins[1][:-1], all_counts[1], color=CB_color_cycle[0], linewidth=3, label='Rtn4-Z')\n",
    "axs[1].step(all_bins[3][:-1], all_counts[3], color=CB_color_cycle[6], linewidth=3, label='Sim-Z')\n",
    "# axs[1].step(0, 0, color=CB_color_cycle[1], linewidth=3, label='Rtn4-tubule')\n",
    "# axs[1].step(0, 0, color=CB_color_cycle[5], linewidth=3, label='Sim-tubule')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "#axs[0].set_xlabel('Angle between cluster axis and tubule-axis')\n",
    "axs[1].set_xlabel('Angle')# between cluster axis and z-axis')\n",
    "axs[1].set_ylim([0,0.02])\n",
    "plt.legend()\n",
    "step_save = savedir + '\\\\step_angles' + ver + '.png'\n",
    "plt.savefig(step_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923afa2-248b-47fa-9f1b-b0ec612b7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(tight_layout=True)\n",
    "plt.step(bins[:-1], all_counts[1])#/all_counts[3])\n",
    "plt.step(bins[:-1], all_counts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7cbab-04fc-403d-a92b-5e37753c1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e636b-bb30-4bec-8939-445ea2ae6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate plot with stats results\n",
    "for ann in range(len(stats_list)):\n",
    "    if ann < len(stats_list)-1:\n",
    "        plt.annotate('', xy=(positions[ann]+0.02,180), xytext=(positions[ann]+0.98,180),\n",
    "                     arrowprops=dict(facecolor='black',arrowstyle=\"-\",connectionstyle=\"bar,fraction=0.2\"))\n",
    "        plt.text(((positions[ann]+positions[ann+1])/2), 210, stars(stats_all[ann][1]),\n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "    else:\n",
    "        plt.annotate('', xy=(0+0.02,220), xytext=(1+0.98,220),\n",
    "                     arrowprops=dict(facecolor='black',arrowstyle=\"-\",connectionstyle=\"bar,fraction=0.1\"))\n",
    "        plt.text(1, 250, stars(stats_all[ann][1]),\n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "# del_list = [0, len(stats_list)-1, \n",
    "# np.delete(combo,\n",
    "# for ann2 in range(len(combo)-(len(stats_list)-1)):\n",
    "#         plt.annotate('', xy=(combo[ann][0]+0.02,180+(20*count2)), xytext=(combo[ann][1]+0.98,180+(20*count2)),\n",
    "#                      arrowprops=dict(facecolor='black',arrowstyle=\"-\",connectionstyle=\"bar,fraction=0.2\"))\n",
    "#         count2 = count2 + 1\n",
    "shape_save = savedir + '\\\\angles_between_axes' + ver + '.png'\n",
    "plt.ylim([0, 260])\n",
    "plt.savefig(shape_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821cd980-ba58-4003-a9d0-524116cdf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887fae7d-0356-4bfe-9b86-5d407f8d2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===================================\n",
    "Violin Plots of Angles between axes\n",
    "===================================\n",
    "used a lot of advice from: \n",
    "https://towardsdatascience.com/making-publication-quality-figures-in-python-part-iv-violin-plot-and-dendrogram-ed0bb8b23ddd\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from scipy.stats import ranksums\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import epps_singleton_2samp\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Statistics\n",
    "from itertools import combinations\n",
    "stats_list = [con_deg, c_deg, con_r_deg]\n",
    "stats_all = np.zeros(len(stats_list),dtype=list)\n",
    "stats_all[0] = ks_2samp(stats_list[0], stats_list[1])\n",
    "stats_all[1] = ks_2samp(stats_list[1], stats_list[2])\n",
    "stats_all[2] = ks_2samp(stats_list[0], stats_list[2])\n",
    "# combo = list(combinations(range(len(stats_list)),2))\n",
    "# for i in range(len(combo)):\n",
    "#     stats_all[i] = ks_2samp(stats_list[combo[i][0]], stats_list[combo[i][1]])\n",
    "\n",
    "\n",
    "\n",
    "def get_whisker(tmp,dataset):\n",
    "    whisker = []\n",
    "    for quantile,data in zip(tmp,dataset):\n",
    "        data = np.array(data)\n",
    "        q1 = quantile[0]\n",
    "        median = quantile[1]\n",
    "        q3 = quantile[2]\n",
    "        iqr = q3 - q1\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        upper = np.clip(upper,q3,data.max())\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        lower = np.clip(lower,data.min(),q1)\n",
    "        whisker.append((upper,lower))\n",
    "    return whisker\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00','#a65628',\n",
    "                  '#f781bf', '#4daf4a',  '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "def stars(p):\n",
    "   if p < 0.0001:\n",
    "       return \"****\"\n",
    "   elif (p < 0.001):\n",
    "       return \"***\"\n",
    "   elif (p < 0.01):\n",
    "       return \"**\"\n",
    "   elif (p < 0.05):\n",
    "       return \"*\"\n",
    "   else:\n",
    "       return \"ns\"\n",
    "\n",
    "count = 0\n",
    "#all_sig = [con_deg,c_deg,con_r_deg]\n",
    "tmp = [np.percentile(data,[25,50,75]) for data in stats_list]\n",
    "whisker = get_whisker(tmp,stats_list)\n",
    "positions = np.linspace(0,len(stats_list)-1,len(stats_list))#[1,2,3,4]\n",
    "fig,ax = plt.subplots(figsize=[12,12])\n",
    "vp = ax.violinplot(dataset=stats_list,positions=positions)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_facecolor(CB_color_cycle[count])\n",
    "    pc.set_edgecolor('black')\n",
    "    count = count + 1\n",
    "    pc.set_linewidth(2)\n",
    "    pc.set_alpha(1)\n",
    "vp['cmaxes'].set_color('black')\n",
    "vp['cmins'].set_color('black')\n",
    "vp['cbars'].set_color('black')\n",
    "                      \n",
    "ax.scatter(positions, [quantile[1] for quantile in tmp],\n",
    "           marker='o', color='white',s=30,zorder=3)\n",
    "ax.vlines(positions, [quantile[0] for quantile in tmp],\n",
    "          [quantile[2] for quantile in tmp],\n",
    "          color='black',linestyle='-',lw=10)\n",
    "ax.vlines(positions,\n",
    "          [bound[0] for bound in whisker],\n",
    "          [bound[1] for bound in whisker],\n",
    "          color='black',linestyle='-',lw=2)\n",
    "plt.xlabel('Principle Axes')\n",
    "plt.ylabel('Degrees')\n",
    "plt.xticks(positions,('Tubule z-axis', 'Tubule axis', 'Random control'))\n",
    "# annotate plot with stats results\n",
    "for ann in range(len(stats_list)):\n",
    "    if ann < len(stats_list)-1:\n",
    "        plt.annotate('', xy=(positions[ann]+0.02,180), xytext=(positions[ann]+0.98,180),\n",
    "                     arrowprops=dict(facecolor='black',arrowstyle=\"-\",connectionstyle=\"bar,fraction=0.2\"))\n",
    "        plt.text(((positions[ann]+positions[ann+1])/2), 210, stars(stats_all[ann][1]),\n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "    else:\n",
    "        plt.annotate('', xy=(0+0.02,220), xytext=(1+0.98,220),\n",
    "                     arrowprops=dict(facecolor='black',arrowstyle=\"-\",connectionstyle=\"bar,fraction=0.1\"))\n",
    "        plt.text(1, 250, stars(stats_all[ann][1]),\n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "# del_list = [0, len(stats_list)-1, \n",
    "# np.delete(combo,\n",
    "# for ann2 in range(len(combo)-(len(stats_list)-1)):\n",
    "#         plt.annotate('', xy=(combo[ann][0]+0.02,180+(20*count2)), xytext=(combo[ann][1]+0.98,180+(20*count2)),\n",
    "#                      arrowprops=dict(facecolor='black',arrowstyle=\"-\",connectionstyle=\"bar,fraction=0.2\"))\n",
    "#         count2 = count2 + 1\n",
    "shape_save = savedir + '\\\\angles_between_axes' + ver + '.png'\n",
    "plt.ylim([0, 260])\n",
    "# plt.savefig(shape_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "#         orientation='portrait', papertype=None, format=None,\n",
    "#         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "#         frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138fe53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot a 2D histogram of the angles between the cluster major axis and the tubule axis (x) and tubule z-axis(y)\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "h, xedges, yedges, image = plt.hist2d(c_tdeg, c_zdeg, bins=24, range=[[0,180],[0,180]], cmap=plt.cm.inferno)#, density=True)\n",
    "plt.xlabel('Angle between cluster axis and tubule axis')\n",
    "plt.ylabel('Angle between cluster axis and tubule z-axis')\n",
    "hist_2d_save = savedir + '\\\\angles_between_axes_2D_histogram' + ver + '.png'\n",
    "# plt.savefig(hist_2d_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "#         orientation='portrait', papertype=None, format=None,\n",
    "#         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "#         frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20db7cc-fb76-496d-932a-e6bda68a9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(c_tdeg,c_zdeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e1897-3b39-408d-ae1e-62faccd88054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a 2D histogram of the cluster center angles to skeleton and angle of cluster axis to skeleton\n",
    "angles_cent_deg = angles_cent_filt * (180/pi)\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "h, xedges, yedges, image = plt.hist2d(cp_tdeg, angles_cent_deg, bins=12, range=[[0,180],[0,180]], cmap=plt.cm.inferno)#, density=True)\n",
    "plt.xlabel('Angle between cluster axis and tubule axis')\n",
    "plt.ylabel('Angle between cluster center and skeleton')\n",
    "hist_2d_save = savedir + '\\\\angles_between_axes_2D_histogram' + ver + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe494b4-01a5-48d7-a53a-cff3b49d0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,10])\n",
    "plt.scatter(c_tdeg, c_zdeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# Plot the standard deviations of each cluster along each principle axis to get a sense for the shape of the clusters\n",
    "# if they are spherical, the histograms would all look similar. If elongated, sigma0 should have a bigger range/median\n",
    "###########################################################################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import pi\n",
    "plt.close(fig=None)\n",
    "sig0_filt = clust['sigma0'][total_filt]\n",
    "sig1_filt = clust['sigma1'][total_filt]\n",
    "sig2_filt = clust['sigma2'][total_filt]\n",
    "max_range = np.around(np.max(clust['sigma0']), decimals=-1)+10\n",
    "n_sig0, bins_sig0, patches_sig0 = plt.hist(x=sig0_filt,bins=20, alpha=0.5, rwidth=0.85, \n",
    "                                           density=True, color=CB_color_cycle[0], label='sigma0', \n",
    "                                           range=[0,max_range])\n",
    "n_sig1, bins_sig1, patches_sig1 = plt.hist(x=sig1_filt,bins=20, alpha=0.5, rwidth=0.85, \n",
    "                                           density=True, color=CB_color_cycle[1], label='sigma1', \n",
    "                                           range=[0,max_range])\n",
    "n_sig2, bins_sig2, patches_sig2 = plt.hist(x=sig2_filt,bins=20, alpha=0.5, rwidth=0.85, \n",
    "                                           density=True, color=CB_color_cycle[2], label='sigma2', \n",
    "                                           range=[0,max_range])\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Normalized # of events')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# Plot the standard deviations of each cluster along each principle axis to get a sense for the shape of the clusters\n",
    "# if they are spherical, the violin plots would all look similar. If elongated, sigma0 should have a bigger range/median\n",
    "###########################################################################################################################\n",
    "vi_colors = ['red','blue','orange']\n",
    "count = 0\n",
    "all_sig = np.transpose(((sig0_filt),(sig1_filt),(sig2_filt)))\n",
    "np.shape(all_sig)\n",
    "all_sig = all_sig.astype(float)\n",
    "violin_dict = plt.violinplot(all_sig, vert=True, showextrema=False, showmedians=True)\n",
    "for pc in violin_dict['bodies']:\n",
    "    pc.set_facecolor(CB_color_cycle[count])\n",
    "    count = count + 1\n",
    "plt.xlabel('Principle Axes')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.xticks((1,2,3),('Sigma0', 'Sigma1', 'Sigma2'))\n",
    "shape_save = savedir + '\\\\cluster_shape' + ver + '.png'\n",
    "plt.savefig(shape_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# Plot sigmax, sigmay, sigmaz to make sure the data is isotropic (this is kind of a proxy since its still looking at \n",
    "# clusters and not beads, but there should be no preference for true x,y,z directions)\n",
    "###########################################################################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import pi\n",
    "plt.close(fig=None)\n",
    "sigx_filt = clust['sigma_x'][total_filt]\n",
    "sigy_filt = clust['sigma_y'][total_filt]\n",
    "sigz_filt = clust['sigma_z'][total_filt]\n",
    "#max_range_xyz = np.around(np.max(clust['sigma0']), decimals=-1)+10\n",
    "n_x, bins_x, patches_x = plt.hist(x=sigx_filt,bins=20, alpha=0.5, rwidth=0.85, density=True, color=CB_color_cycle[0],\n",
    "                                           label='axis0-x', range=[0,70])\n",
    "n_y, bins_y, patches_y = plt.hist(x=sigy_filt,bins=20, alpha=0.5, rwidth=0.85, density=True, color=CB_color_cycle[1],\n",
    "                                           label='axis0-y', range=[0,70])\n",
    "n_z, bins_z, patches_z = plt.hist(x=sigz_filt,bins=20, alpha=0.5, rwidth=0.85, density=True, color=CB_color_cycle[2],\n",
    "                                           label='axis0-z', range=[0,70])\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Normalized # of events')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde08df1-8836-47cd-b808-59b51ce81335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine closest mesh vertex to each skeleton point\n",
    "dist, ind = tree_surf.query(skeleton, k=1)\n",
    "ss_vecs = skeleton - surf_verts[ind]\n",
    "ss_vecs_norm = ss_vecs/np.linalg.norm(ss_vecs,axis=1)[:,None]\n",
    "ss_long_vecs = np.cross(vecs_hat,ss_vecs_norm)\n",
    "ss_vecs_norm_filt = ss_vecs_norm[skel_cent_ind]\n",
    "ss_vecs_norm_filt = ss_vecs_norm_filt[total_filt]\n",
    "ss_long_vecs_filt = ss_long_vecs[skel_cent_ind]\n",
    "ss_long_vecs_filt = ss_long_vecs_filt[total_filt]\n",
    "\n",
    "r1_angs = np.zeros(len(frame0_cent_filt))\n",
    "r2_angs = np.zeros(len(frame0_cent_filt))\n",
    "for h in range(len(frame0_cent_filt)):\n",
    "    # Take arccos of the dot product to get the angle out\n",
    "    r1_angs[h] = np.arccos(np.dot(ss_long_vecs_filt[h],clust_filt[h]))\n",
    "    r2_angs[h] = np.arccos(np.dot(ss_vecs_norm_filt[h],clust_filt[h]))\n",
    "\n",
    "plt.hist2d(r1_angs,r2_angs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_colors = ['red','green','blue']\n",
    "count = 0\n",
    "all_sigxyz = np.transpose(((sigx_filt),(sigy_filt),(sigz_filt)))\n",
    "np.shape(all_sigxyz)\n",
    "all_sigxyz = all_sigxyz.astype(float)\n",
    "violin_dict = plt.violinplot(all_sigxyz, vert=True, showextrema=False, showmedians=True)\n",
    "for pc in violin_dict['bodies']:\n",
    "    pc.set_facecolor(CB_color_cycle[count])\n",
    "    count = count + 1\n",
    "plt.xlabel('Cartesian Axes')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.xticks((1,2,3),('Sigmax', 'Sigmay', 'Sigmaz'))\n",
    "lp_save = savedir + '\\\\xyz_sigma' + ver + '.png'\n",
    "plt.savefig(lp_save, dpi=600, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad7e0c-a25b-4579-933f-9b9bd70346a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fceebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import pi\n",
    "plt.close(fig=None)\n",
    "n_ani, bins_ani, patches_ani = plt.hist(x=clust['anisotropy'],bins=20, alpha=0.5, rwidth=0.85, density=True, color='purple',\n",
    "                                           label='anisotropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TROUBLESHOOTING STUFF -Testing from here down\n",
    "# #add_ds_from_Nx3(skeleton_rtn[skel_ind_cent], pipeline, pymevis, 'skeleton-used', normals=frame0_cent)\n",
    "# # c_dot_ind = c_dot == 0\n",
    "# # c_dot_zeros = centers[c_dot_ind]\n",
    "# # sum(c_dot_ind)\n",
    "# # import pickle\n",
    "# skel_dict = {'skeleton': skeleton_rtn, 'e0':e0_rtn, 'e1': e1_rtn, 'e2': e2_rtn}\n",
    "# # skel_save = savedir + '\\\\skeleton.pickle'\n",
    "# # file_to_save = open(skel_save,\"wb\")\n",
    "# # pickle.dump(skel_save, file_to_save)\n",
    "# # file_to_save.close()\n",
    "# type(skel_dict['skeleton'])\n",
    "\n",
    "\n",
    "# translate so origins of vectors are the same\n",
    "# newvector = skeleton_origin - myvectors_origin\n",
    "# translatedvector = myvectors_origin + newvector\n",
    "\n",
    "# do this instead of translation\n",
    "# project cluster vector into the plane created by e2 and frame2 and dot it with frame2(1: orthogonal to tube, 0: parallel)\n",
    "\n",
    "# projection operator: outer product of 2 unit normal vector\n",
    "# outer product of normalized e2 and frame2 (e2_norm[:,:,None]*frame2_norm[:,None,:])\n",
    "# 'None' tells it which dimenions to broadcast over\n",
    "oprod = frame0_cent[:,:,None]*frame2_cent_norm[:,None,:]\n",
    "# Then do projection matrix (3by3) time the cluster vector (3by1) to get projection\n",
    "proj = oprod*clust['axis0'][:,:,None]\n",
    "# Then dot it with e2_norm (0: orthogonal) or frame2_norm (1: orthogonal) (just have them all normalized before dotting)\n",
    "np.shape(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# Messing around with plotting all the clusters on top of each other\n",
    "###########################################################################################################################\n",
    "\n",
    "all_data = np.genfromtxt(all_data, delimiter = ',')\n",
    "all_clust = {\"t\": all_data[:,1], \"nPhotons\": all_data[:,5], \"x\": all_data[:,25], \"y\": all_data[:,23], \n",
    "        \"z\": all_data[:,9], \"clumpIndex\": all_data[:,26], \"clumpSize\": all_data[:,27], \"objectID\": all_data[:,29], \n",
    "        \"NEvents\": all_data[:,30]}\n",
    "\n",
    "# Pseudo-code for finding coordinates of all points in each cluster and organizing them by cluster\n",
    "# Idea 1:\n",
    "# - basic slow way: loop over data from 0 to number of clusters\n",
    "# - create boolean for each objectID, filter out points not in that cluster and assign the ones that \n",
    "#   are to an array\n",
    "#\n",
    "# Idea 2:\n",
    "# - Loop over each data point (about 30k)\n",
    "# - Identify objectID for that point\n",
    "# - Assign the x,y,z coordinates of the point to a list of arrays indexed to that objectID\n",
    "# - list of arrays will be initialized with length = # of clusters(highest objectID)\n",
    "\n",
    "# Attempt at Idea 2:\n",
    "# initialize list that will hold all the coordinates with each index being a unique cluster\n",
    "id_max = int(np.max(all_clust['objectID']))\n",
    "c_coords = np.empty(id_max+1, dtype=list)\n",
    "ind_set = set()\n",
    "for g in range(len(all_clust['x'])):\n",
    "    ind = int(all_clust['objectID'][g])\n",
    "    x = all_clust['x'][g]\n",
    "    y = all_clust['y'][g]\n",
    "    z = all_clust['z'][g]\n",
    "    xyz = [x,y,z]\n",
    "    if not ind in ind_set:\n",
    "        c_coords[ind] = xyz\n",
    "    else:\n",
    "        c_coords[ind] = np.vstack((c_coords[ind], xyz))\n",
    "    ind_set.add(ind)\n",
    "    del ind, x, y, z, xyz\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "centered = np.zeros(id_max, dtype=list)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection = '3d')\n",
    "for h in range(1,id_max):\n",
    "    if np.shape(c_coords[h]) and np.shape(c_coords[h]) > (3,):\n",
    "        # calculate genters of clusters and translate all points to be centered around [0,0,0]\n",
    "        cgx = np.sum(c_coords[h][:,0])/len(c_coords[h])\n",
    "        cgy = np.sum(c_coords[h][:,1])/len(c_coords[h])\n",
    "        cgz = np.sum(c_coords[h][:,2])/len(c_coords[h])\n",
    "        centered[h] = c_coords[h] - [cgx, cgy, cgz]\n",
    "        ax.scatter3D(centered[h][:,0], centered[h][:,1], centered[h][:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69124280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incomplete defining a function to do all this\n",
    "def cluster_analysis(c_measures, points):\n",
    "    '''\n",
    "    '''\n",
    "    c_data = np.genfromtxt(c_measures, delimiter = ',')\n",
    "    clust = {\"count\": c_data[:,0], \"x\": c_data[:,1], \"y\": c_data[:,2], \"z\": c_data[:,3], \"gyrationRadius\": c_data[:,4], \n",
    "            \"median_abs_deviation\": c_data[:,5], \"sigma0\": c_data[:,9], \"sigma1\": c_data[:,10], \"sigma2\": c_data[:,11], \n",
    "            \"sigma_x\": c_data[:,12], \"sigma_y\": c_data[:,13], \"sigma_z\": c_data[:,14], \"anisotropy\": c_data[:,15], \n",
    "            \"theta\": c_data[:,16], \"phi\": c_data[:,17]}\n",
    "\n",
    "    #making save-folder if it doesn't exist (DON'T TOUCH THE NEXT 5 LINES)\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "    p = Path(savedir)\n",
    "    if not p.exists():\n",
    "        os.mkdir(savedir)\n",
    "    workdir = os.getcwd()\n",
    "\n",
    "    import pandas as pd\n",
    "    import copy\n",
    "\n",
    "    if 'check1' in locals():\n",
    "        del check1\n",
    "    if 'check2' in locals():\n",
    "        del check2\n",
    "    if 'x' in locals():\n",
    "        del x\n",
    "    if 'y' in locals():\n",
    "        del y\n",
    "    if 'z' in locals():\n",
    "        del z\n",
    "\n",
    "    # Initialize variables\n",
    "    csv_file = pd.read_csv(datadir, sep=',', header=None)\n",
    "    # clusto[\"axis0\"] = np.copy(csv_file[6][1:].values)\n",
    "    # clusto[\"axis1\"] = np.copy(csv_file[7][1:].values)\n",
    "    # clusto[\"axis2\"] = np.copy(csv_file[8][1:].values)\n",
    "    clusto = {\"axis0\": np.copy(csv_file[6][1:].values), \"axis1\": np.copy(csv_file[7][1:].values), \n",
    "              \"axis2\": np.copy(csv_file[8][1:].values)}\n",
    "    clust['axis0'] = np.zeros((len(clust['count']),3))\n",
    "    clust['axis1'] = np.zeros((len(clust['count']),3))\n",
    "    clust['axis2'] = np.zeros((len(clust['count']),3))\n",
    "    # clust = {\"axis0\": np.copy(csv_file[6][1:].values), \"axis1\": np.copy(csv_file[7][1:].values),\n",
    "    #         \"axis2\": np.copy(csv_file[8][1:].values)}\n",
    "    # clust = {\"count\": np.copy(c_data[0][1:].values), \"x\": np.copy(c_data[1][1:].values), \"y\": np.copy(c_data[2][1:].values), \n",
    "    #         \"z\": np.copy(c_data[3][1:].values), \"gyrationRadius\": np.copy(c_data[4][1:].values), \n",
    "    #         \"median_abs_deviation\": np.copy(c_data[5][1:].values), \"axis0\": np.copy(c_data[6][1:].values), \n",
    "    #         \"axis1\": np.copy(c_data[7][1:].values), \"axis2\": np.copy(c_data[8][1:].values), \n",
    "    #         \"sigma0\": np.copy(c_data[9][1:].values), \"sigma1\": np.copy(c_data[10][1:].values), \n",
    "    #         \"sigma2\": np.copy(c_data[11][1:].values), \"sigma_x\": np.copy(c_data[12][1:].values),\n",
    "    #         \"sigma_y\": np.copy(c_data[13][1:].values), \"sigma_z\": np.copy(c_data[14][1:].values), \n",
    "    #         \"anisotropy\": np.copy(c_data[15][1:].values), \"theta\": np.copy(c_data[16][1:].values), \n",
    "    #         \"phi\": np.copy(c_data[17][1:].values)}\n",
    "    #clust2 = copy.deepcopy(clust)\n",
    "\n",
    "    # Convert 'axis0', 'axis1', and 'axis2' values to floats from strings\n",
    "    # axis0\n",
    "    for a in range(len(clusto[\"axis0\"])):\n",
    "        #print('a:',a)\n",
    "        if a > 0:\n",
    "            del x,y,z,check1,check2\n",
    "        if clusto['axis0'][a][2:4] == '[ ': ##### need a different way of parsing the data\n",
    "            for b in range(1,len(clusto['axis0'][a])):\n",
    "                if clusto['axis0'][a][b] == ' ' and 'check1' not in locals():\n",
    "                    #print('b:',b)\n",
    "                    check1 = b\n",
    "                elif clusto['axis0'][a][b] == ' ' and 'check2' not in locals():\n",
    "                    #print('x - b:',b)\n",
    "                    x = float(clusto['axis0'][a][3:b])\n",
    "                    check2 = b\n",
    "                elif clusto['axis0'][a][b] == ' ' and clusto['axis0'][a][b-1] != ' ' and 'check2' in locals() and 'y' not in locals():             \n",
    "                    #print('yz - b:',b)\n",
    "                    y = float(clusto['axis0'][a][check2:b])\n",
    "                    z = float(clusto['axis0'][a][b:-2])\n",
    "                    #check2 = b\n",
    "        elif clusto['axis0'][a][2] == '[' and clusto['axis0'][a][3] != ' ': ####resume here\n",
    "            for b in range(1,len(clusto['axis0'][a])):\n",
    "                if clusto['axis0'][a][b] == ' ' and 'check1' not in locals():\n",
    "                    #print('2x b:',b)\n",
    "                    check1 = b\n",
    "                    x = float(clusto['axis0'][a][3:b])\n",
    "                elif clusto['axis0'][a][b] == ' ' and clusto['axis0'][a][b-1] != ' ' and 'check2' not in locals() and 'y' not in locals():# 'check2' not in locals():\n",
    "                    #print('2yz - b:',b)\n",
    "                    y = float(clusto['axis0'][a][check1:b])\n",
    "                    z = float(clusto['axis0'][a][b:-2])\n",
    "                    check2 = b\n",
    "        clust['axis0'][a] = np.array([x, y, z])\n",
    "    #     clust['axis0'][a][0] = x\n",
    "    #     clust['axis0'][a][1] = y\n",
    "    #     clust['axis0'][a][2] = z\n",
    "    del check1, check2, x, y, z, a, b\n",
    "\n",
    "    # axis1\n",
    "    for c in range(len(clusto[\"axis1\"])):\n",
    "        #print('c:',c)\n",
    "        if c > 0:\n",
    "            del x,y,z,check1,check2\n",
    "        if clusto['axis1'][c][2:4] == '[ ': ##### need a different way of parsing the data\n",
    "            for d in range(1,len(clusto['axis1'][c])):\n",
    "                if clusto['axis1'][c][d] == ' ' and 'check1' not in locals():\n",
    "                    #print('d:',d)\n",
    "                    check1 = d\n",
    "                elif clusto['axis1'][c][d] == ' ' and 'check2' not in locals():\n",
    "                    #print('x - d:',d)\n",
    "                    x = float(clusto['axis1'][c][3:d])\n",
    "                    check2 = d\n",
    "                elif clusto['axis1'][c][d] == ' ' and clusto['axis1'][c][d-1] != ' ' and 'check2' in locals() and 'y' not in locals():             \n",
    "                    #print('yz - d:',d)\n",
    "                    y = float(clusto['axis1'][c][check2:d])\n",
    "                    z = float(clusto['axis1'][c][d:-2])\n",
    "                    #check2 = d\n",
    "        elif clusto['axis1'][c][2] == '[' and clusto['axis1'][c][3] != ' ': ####resume here\n",
    "            for d in range(1,len(clusto['axis1'][c])):\n",
    "                if clusto['axis1'][c][d] == ' ' and 'check1' not in locals():\n",
    "                    #print('2x d:',d)\n",
    "                    check1 = d\n",
    "                    x = float(clusto['axis1'][c][3:d])\n",
    "                elif clusto['axis1'][c][d] == ' ' and clusto['axis1'][c][d-1] != ' ' and 'check2' not in locals() and 'y' not in locals():# 'check2' not in locals():\n",
    "                    #print('2yz - d:',d)\n",
    "                    y = float(clusto['axis1'][c][check1:d])\n",
    "                    z = float(clusto['axis1'][c][d:-2])\n",
    "                    check2 = d\n",
    "        clust['axis1'][c] = np.array([x, y, z])\n",
    "    del check1, check2, x, y, z, c, d\n",
    "\n",
    "    # axis2\n",
    "    for e in range(len(clusto[\"axis2\"])):\n",
    "        #print('c:',c)\n",
    "        if e > 0:\n",
    "            del x,y,z,check1,check2\n",
    "        if clusto['axis2'][e][2:4] == '[ ': ##### need a different way of parsing the data\n",
    "            for f in range(1,len(clusto['axis2'][e])):\n",
    "                if clusto['axis2'][e][f] == ' ' and 'check1' not in locals():\n",
    "                    #print('f:',f)\n",
    "                    check1 = f\n",
    "                elif clusto['axis2'][e][f] == ' ' and 'check2' not in locals():\n",
    "                    #print('x - f:',f)\n",
    "                    x = float(clusto['axis2'][e][3:f])\n",
    "                    check2 = f\n",
    "                elif clusto['axis2'][e][f] == ' ' and clusto['axis2'][e][f-1] != ' ' and 'check2' in locals() and 'y' not in locals():             \n",
    "                    #print('yz - f:',f)\n",
    "                    y = float(clusto['axis2'][e][check2:f])\n",
    "                    z = float(clusto['axis2'][e][f:-2])\n",
    "                    #check2 = f\n",
    "        elif clusto['axis2'][e][2] == '[' and clusto['axis2'][e][3] != ' ': ####resume here\n",
    "            for f in range(1,len(clusto['axis2'][e])):\n",
    "                if clusto['axis2'][e][f] == ' ' and 'check1' not in locals():\n",
    "                    #print('2x f:',f)\n",
    "                    check1 = f\n",
    "                    x = float(clusto['axis2'][e][3:f])\n",
    "                elif clusto['axis2'][e][f] == ' ' and clusto['axis2'][e][f-1] != ' ' and 'check2' not in locals() and 'y' not in locals():# 'check2' not in locals():\n",
    "                    #print('2yz - f:',f)\n",
    "                    y = float(clusto['axis2'][e][check1:f])\n",
    "                    z = float(clusto['axis2'][e][f:-2])\n",
    "                    check2 = f\n",
    "        clust['axis2'][e] = np.array([x, y, z])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyme",
   "language": "python",
   "name": "pyme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
